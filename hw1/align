#!/usr/bin/env python
import optparse, sys, math
from collections import defaultdict
from pprint import pprint
from math import log

import random

optparser = optparse.OptionParser()
optparser.add_option("-b", "--bitext", dest="bitext", default="data/dev-test-train.de-en", help="Parallel corpus (default data/dev-test-train.de-en)")
optparser.add_option("-t", "--threshold", dest="threshold", default=0.5, type="float", help="Threshold for aligning with Dice's coefficient (default=0.5)")
optparser.add_option("-n", "--num_sentences", dest="num_sents", default=sys.maxint, type="int", help="Number of sentences to use for training and alignment")
optparser.add_option("-i", "--EM_iterations", dest="EM_iter", default=1, type="int", help="Number of iterations of EM to use")

(opts, _) = optparser.parse_args()


bitext = [[sentence.strip().split() for sentence in pair.split(' ||| ')] for pair in open(opts.bitext)][:opts.num_sents]
alignment_table = {}
alignments = []

f_intern = {}
f_increment = 0

e_intern = {}
e_increment = 0

bitext_intern = []

for (f_s, e_s) in bitext:
  f_s = ["NULL"] + f_s

  f_new = []
  e_new = []
  for f in f_s:
    if f_intern.get(f,None) == None:
      f_intern[f] = f_increment
      f_increment += 1
    f_new.append(f_intern[f])

  for e in e_s:
    if e_intern.get(e,None) == None:
      e_intern[e] = e_increment
      e_increment += 1

    e_new.append(e_intern[e])
  bitext_intern.append([f_new, e_new])

bitext = None

unif_e_words = 1.0 / e_increment
t = {}
for f_word in xrange(f_increment):
  t[f_word] = {}

sys.stderr.write("Finished initializing t(f|e)\n")

for EM in xrange(opts.EM_iter):
  sys.stderr.write("Beginning EM iteration "+str(EM+1)+"\n")
  sys.stderr.write("M STEP \n")
  count = {}
  total = defaultdict(int)
  for (f_s, e_s) in bitext_intern:
    for f in f_s:
      count[f] = count.get(f, defaultdict(float))

    for e in e_s:
      if EM == 0:
        SUM = sum([unif_e_words for f in f_s])
      else:
        SUM = sum([t[f][e] for f in f_s])

      for f in f_s:
        if EM == 0:
          count[f][e] += unif_e_words / SUM
          total[f] += unif_e_words / SUM
        else:
          count[f][e] += t[f][e] / SUM
          total[f] += t[f][e] / SUM

      #count[f][e] += t[f][e] / total_s[e]# + (1. / (1 + abs(i-j)))
      #total[f] += t[f][e] / total_s[e]# + (1. / (1 + abs(i-j)))
      
  sys.stderr.write("E STEP \n")

  t = {}
  for (f_s, e_s) in bitext_intern:
    for f in f_s:
      t[f] = t.get(f, {})
      for e in e_s:
        if count[f][e] > 0:
          #sys.stderr.write(str(count[f][e])+"\n")
          t[f][e] = count[f][e] / total[f]


sys.stderr.write("Finished EM. Writing out alignments.\n")
for (f_s, e_s) in bitext_intern:
  align_sent = []
  for i,e in enumerate(e_s):
    
    max_p = -1
    max_index = -1
    for j,f in enumerate(f_s):
      p = t[f][e]
      
      if p > max_p or max_p == -1:
        max_p = p
        max_index = j

    a_i = max_index - 1
    if a_i != -1:
      align_sent.append((a_i, i))
    #else:
    #  sys.stderr.write(str(a_i) + " " + str(f_s[a_i+1]) + " " + str(f_lookup[f_s[a_i+1]]) + "\n")


  print " ".join([str(i)+"-"+str(j) for i,j in align_sent])

